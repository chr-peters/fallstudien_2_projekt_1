---
title: "XGBoost"
output:
  pdf_document:
    toc: true
    toc_depth: 2
    number_sections: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r, message=FALSE}
library(tidyverse)
library(ggplot2)

library(mlr3)
library(mlr3learners)
library(mlr3pipelines)
library(mlr3tuning)
library(mlr3filters)
library(paradox)
```

```{r, results = "hide", message = FALSE, warning = FALSE}
future::plan("multiprocess")
```

# Vorhersage der Upload-Raten

## Einlesen der Daten

```{r}
data_dir = "../datasets/"
results_dir = "../prediction_results/"
```

```{r}
dataset_ul = read_csv(
  str_c(data_dir, "dataset_ul.csv"), 
  col_types = cols(
    drive_id = col_integer(),
    scenario = col_factor(), 
    provider = col_factor(), 
    ci = col_factor(), 
    enodeb = col_factor()
  )
) %>% select(
  drive_id,
  timestamp,
  scenario,
  provider,
  velocity_mps,
  rsrp_dbm,
  rsrq_db,
  rssnr_db,
  cqi,
  ta,
  enodeb,
  f_mhz,
  payload_mb,
  throughput_mbits
) %>% drop_na() %>% rowid_to_column(var="row_id_original")
```

```{r}
dataset_ul_o2 = filter(dataset_ul, provider=="o2")
glimpse(dataset_ul_o2)

dataset_ul_tmobile = filter(dataset_ul, provider=="tmobile")
glimpse(dataset_ul_tmobile)

dataset_ul_vodafone = filter(dataset_ul, provider=="vodafone")
glimpse(dataset_ul_vodafone)
```

## Vorhersage-Tasks für jeden Provider

Im Folgenden wird mit dem `mlr3` Paket gearbeitet. Dieses setzt voraus, dass
für eine Vorhersage ein sogenannter `Task` erzeugt wird, was im Folgenden
geschieht.
```{r}
make_task = function(dataset, task_id, target="throughput_mbits") {
  task = TaskRegr$new(
    id = task_id,
    backend = dataset %>% select(-drive_id, -timestamp, -provider, -scenario),
    target = target
  )
  
  task$col_roles$name = "row_id_original"
  task$col_roles$feature = setdiff(task$col_roles$feature, "row_id_original")
  
  return(task)
}

task_ul_o2 = make_task(dataset_ul_o2, "task_ul_o2")
task_ul_o2

task_ul_tmobile = make_task(dataset_ul_tmobile, "task_ul_tmobile")
task_ul_tmobile

task_ul_vodafone = make_task(dataset_ul_vodafone, "task_ul_vodafone")
task_ul_vodafone
```

## Splitting Strategien für das Validierungsverfahren

Das "outer resampling" beschreibt die Aufteilung in einen Trainings- und
einen Testdatensatz. Im konkreten Fall werden für die Trainingsdaten die
Fahrten 1-7 und für die Testdaten die Fahrten 8-10 eingesetzt.
```{r}
get_row_ids_by_drive_ids = function(task, dataset, drive_ids) {
  result = (tibble(task$row_names) %>% 
    inner_join(dataset, by=c("row_name"="row_id_original")) %>%
    filter(drive_id %in% drive_ids))$row_id
  return(result)
}

make_outer_resampling = function(task, dataset, drive_ids_train, drive_ids_test) {
  row_ids_train = get_row_ids_by_drive_ids(task, dataset, drive_ids_train)
  row_ids_test = get_row_ids_by_drive_ids(task, dataset, drive_ids_test)
  
  result = rsmp("custom")
  result$instantiate(
    task, 
    train_sets=list(row_ids_train), 
    test_sets=list(row_ids_test)
  )
  
  return(result)
}
```

Das "inner resampling" implementiert das an die Zeitreihenkreuzvalidierung
angelehnte Verfahren, welches beim Parametertuning zum Einsatz kommt:
```{r}
make_inner_resampling = function(task, dataset, last_drive_id) {
  train_sets = list()
  test_sets = list()
  
  for (cur_last_drive_id_train in 2:(last_drive_id-1)) {
    drive_ids_train = 1:cur_last_drive_id_train
    drive_ids_test = cur_last_drive_id_train + 1
    
    row_ids_train = get_row_ids_by_drive_ids(task, dataset, drive_ids_train)
    row_ids_test = get_row_ids_by_drive_ids(task, dataset, drive_ids_test)
    
    train_sets[[length(train_sets)+1]] = row_ids_train
    test_sets[[length(test_sets)+1]] = row_ids_test
  }
  
  result = rsmp("custom")
  result$instantiate(task, train_sets=train_sets, test_sets=test_sets)
  
  return(result)
}
```

## Erzeugung der Vorhersagepipeline

```{r}
make_learner = function(nrounds=100, eta=NULL, gamma=NULL, lambda=NULL) {
  factor_encoding = po(
    "encode",
    method = "one-hot",
    affect_columns = selector_type("factor")
  )
  xgboost = lrn("regr.xgboost")
  
  if (!is.null(nrounds)) {
    xgboost$param_set$values = mlr3misc::insert_named(
      xgboost$param_set$values,
      list(nrounds=nrounds)
    )
  }
  if (!is.null(eta)) {
    xgboost$param_set$values = mlr3misc::insert_named(
      xgboost$param_set$values,
      list(eta=eta)
    )
  }
  if (!is.null(gamma)) {
    xgboost$param_set$values = mlr3misc::insert_named(
      xgboost$param_set$values,
      list(gamma=gamma)
    )
  }
  if (!is.null(lambda)) {
    xgboost$param_set$values = mlr3misc::insert_named(
      xgboost$param_set$values,
      list(lambda=lambda)
    )
  }
  
  pipe = factor_encoding %>>% PipeOpLearner$new(xgboost)
  learner = GraphLearner$new(pipe)
  return(learner)
}
```

Hier ist die Vorhersage-Pipeline einmal schematisch dargestellt.
Bevor der xgboost Algorithmus eingesetzt werden kann, müssen allerdings
Faktorstufen kodiert werden. Dies geschieht hier mit der one-hot-encoding
Methode.
```{r}
make_learner()$graph$plot()
```

## Parameter Tuning

Der Suchraum wird wie folgt definiert:
```{r}
parameter_space = ParamSet$new(list(
  ParamInt$new("regr.xgboost.nrounds", lower=100, upper=1000),
  ParamDbl$new("regr.xgboost.eta", lower=0.01, upper=1),
  ParamDbl$new("regr.xgboost.gamma", lower=0, upper=10),
  ParamDbl$new("regr.xgboost.lambda", lower=0, upper=10)
))
```

Die folgende Funktion führt das Parameter-Tuning für einen gegebenen
Datensatz durch:
```{r}
get_tuning_result = function(task, dataset, grid_resolution, n_evals) {
  tuning_instance = TuningInstanceSingleCrit$new(
    task = task,
    learner = make_learner(),
    resampling = make_inner_resampling(task, dataset, last_drive_id=7),
    measure = msr("regr.mae"),
    terminator = trm("evals", n_evals=n_evals),
    search_space = parameter_space$clone(deep = TRUE),
    store_benchmark_result = TRUE,
    check_values = TRUE
  )
  
  tuner = tnr("grid_search", resolution = grid_resolution)
  tuner$optimize(tuning_instance)
  
  return(tuning_instance)
}
```

Nun kann der Tuning-Prozess für jeden Provider gestartet werden:
```{r, results = "hide"}
tuning_evals_ul = 50

tuning_result_ul_o2 = get_tuning_result(
  task_ul_o2,
  dataset_ul,
  grid_resolution = 20,
  n_evals = tuning_evals_ul
)
tuning_result_ul_tmobile = get_tuning_result(
  task_ul_tmobile,
  dataset_ul,
  grid_resolution = 20,
  n_evals = tuning_evals_ul
)
tuning_result_ul_vodafone = get_tuning_result(
  task_ul_vodafone,
  dataset_ul,
  grid_resolution = 20,
  n_evals = tuning_evals_ul
)
```

Die resultierenden Hyperparameter seien im Folgenden aufgeführt:
```{r}
tuning_result_ul = bind_rows(
  tibble(tuning_result_ul_o2$result) %>% mutate(provider="o2"),
  tibble(tuning_result_ul_tmobile$result) %>% mutate(provider="tmobile"),
  tibble(tuning_result_ul_vodafone$result) %>% mutate(provider="vodafone"),
) %>% select(
  "provider",
  "regr.xgboost.nrounds",
  "regr.xgboost.eta",
  "regr.xgboost.gamma",
  "regr.xgboost.lambda"
)

knitr::kable(tuning_result_ul)
```

## Parametrisierung der Lernalgorithmen mit den gefundenen Hyperparametern

```{r}
learner_ul_o2 = make_learner(
  nrounds = tuning_result_ul_o2$result$regr.xgboost.nrounds,
  eta = tuning_result_ul_o2$result$regr.xgboost.eta,
  gamma = tuning_result_ul_o2$result$regr.xgboost.gamma,
  lambda = tuning_result_ul_o2$result$regr.xgboost.lambda
)

learner_ul_tmobile = make_learner(
  nrounds = tuning_result_ul_tmobile$result$regr.xgboost.nrounds,
  eta = tuning_result_ul_tmobile$result$regr.xgboost.eta,
  gamma = tuning_result_ul_tmobile$result$regr.xgboost.gamma,
  lambda = tuning_result_ul_tmobile$result$regr.xgboost.lambda
)

learner_ul_vodafone = make_learner(
  nrounds = tuning_result_ul_vodafone$result$regr.xgboost.nrounds,
  eta = tuning_result_ul_vodafone$result$regr.xgboost.eta,
  gamma = tuning_result_ul_vodafone$result$regr.xgboost.gamma,
  lambda = tuning_result_ul_vodafone$result$regr.xgboost.lambda
)
```

## Validierung

```{r, results = "hide"}
resampling_result_ul_o2 = resample(
  task = task_ul_o2,
  learner = learner_ul_o2,
  resampling = make_outer_resampling(
    task_ul_o2, 
    dataset_ul, 
    drive_ids_train=1:7, 
    drive_ids_test=8:10
  ),
  store_models = TRUE
)

resampling_result_ul_tmobile = resample(
  task = task_ul_tmobile,
  learner = learner_ul_tmobile,
  resampling = make_outer_resampling(
    task_ul_tmobile,
    dataset_ul,
    drive_ids_train=1:7,
    drive_ids_test=8:10
  ),
  store_models = TRUE
)

resampling_result_ul_vodafone = resample(
  task = task_ul_vodafone,
  learner = learner_ul_vodafone,
  resampling = make_outer_resampling(
    task_ul_vodafone,
    dataset_ul,
    drive_ids_train=1:7,
    drive_ids_test=8:10
  ),
  store_models = TRUE
)
```

Im Folgenden werden die im Zuge der Validierung ermittelten Out-of-Sample Resultate
zur späteren Berechnung der Performance-Maße als neue Spalte an die Original-Datensätze angehängt:
```{r}
predictions_ul_o2 = as.data.table(resampling_result_ul_o2$prediction())
glimpse(tibble(predictions_ul_o2))
predictions_ul_tmobile = as.data.table(resampling_result_ul_tmobile$prediction())
predictions_ul_vodafone = as.data.table(resampling_result_ul_vodafone$prediction())
```

```{r}
validation_results_ul = bind_rows(
  tibble(predictions_ul_o2) %>% 
    inner_join(tibble(task_ul_o2$row_names), by="row_id") %>% 
    inner_join(dataset_ul, by=c("row_name"="row_id_original")),
  tibble(predictions_ul_tmobile) %>% 
    inner_join(tibble(task_ul_tmobile$row_names), by="row_id") %>% 
    inner_join(dataset_ul, by=c("row_name"="row_id_original")),
  tibble(predictions_ul_vodafone) %>% 
    inner_join(tibble(task_ul_vodafone$row_names), by="row_id") %>% 
    inner_join(dataset_ul, by=c("row_name"="row_id_original"))
)
glimpse(validation_results_ul)
```

```{r}
all(validation_results_ul$truth == validation_results_ul$throughput_mbits)
```

Diese können dann optional als .csv Datei gespeichert werden.
```{r}
validation_results_ul = validation_results_ul %>% 
  rename(prediction_xgboost=response) %>% 
  select(-truth, -row_id, -row_name)

# write_csv(validation_results_ul, str_c(results_dir, "predictions_xgboost_ul.csv"))
```

### Scatter Plots

```{r}
ggplot(
  filter(validation_results_ul, provider=="o2"),
  aes(x=throughput_mbits, y=prediction_xgboost)
) +
  geom_point(aes(color=scenario, shape=scenario)) +
  xlab("Measured Data Rate [MBit/s]") +
  ylab("Predicted Data Rate [MBit/s]") +
  ggtitle("Upload-Rate Predictions for Provider O2")
```

```{r}
ggplot(
  filter(validation_results_ul, provider=="tmobile"),
  aes(x=throughput_mbits, y=prediction_xgboost)
) +
  geom_point(aes(color=scenario, shape=scenario)) +
  xlab("Measured Data Rate [MBit/s]") +
  ylab("Predicted Data Rate [MBit/s]") +
  ggtitle("Upload-Rate Predictions for Provider T-Mobile")
```

```{r}
ggplot(
  filter(validation_results_ul, provider=="vodafone"),
  aes(x=throughput_mbits, y=prediction_xgboost)
) +
  geom_point(aes(color=scenario, shape=scenario)) +
  xlab("Measured Data Rate [MBit/s]") +
  ylab("Predicted Data Rate [MBit/s]") +
  ggtitle("Upload-Rate Predictions for Provider Vodafone")
```

## Relevanz der Kovariablen

### Permutation Feature Importance

Die folgende Funktion ist ein kleiner "Hack", welcher dafür sorgt, dass das in
`mlr3` implementierte Permutation Feature Imortance Maß auch mit einem custom resampling
funktioniert.
```{r}
uninstantiate_resampling = function(resampling) {
  new_resampling = new.env()
  class(new_resampling) = class(resampling)
  for (val in ls(resampling, all.names = TRUE)) {
    if (val != "is_instantiated") {
      assign(val, get(val, envir=resampling), envir = new_resampling)
    }
  }
  new_resampling$is_instantiated = FALSE
  
  return(new_resampling)
}
```

```{r, results='hide'}
num_permutation_sims_ul = 5

filter_permutation_o2_ul = flt("permutation",
  learner = learner_ul_o2$clone(),
  resampling = uninstantiate_resampling(
    make_outer_resampling(
      task_ul_o2,
      dataset_ul,
      drive_ids_train=1:7,
      drive_ids_test=8:10
    )
  ),
  measure = msr("regr.mae"),
  standardize = TRUE,
  nmc=num_permutation_sims_ul
)
filter_permutation_o2_ul$calculate(task_ul_o2)
permutation_ul_o2 = tibble(
  as.data.table(filter_permutation_o2_ul)
) %>% mutate(provider="o2")

filter_permutation_tmobile_ul = flt("permutation",
  learner = learner_ul_tmobile$clone(),
  resampling = uninstantiate_resampling(
    make_outer_resampling(
      task_ul_tmobile,
      dataset_ul,
      drive_ids_train=1:7,
      drive_ids_test=8:10
    )
  ),
  measure = msr("regr.mae"),
  standardize = TRUE,
  nmc=num_permutation_sims_ul
)
filter_permutation_tmobile_ul$calculate(task_ul_tmobile)
permutation_ul_tmobile = tibble(
  as.data.table(filter_permutation_tmobile_ul)
) %>% mutate(provider="tmobile")

filter_permutation_vodafone_ul = flt("permutation",
  learner = learner_ul_vodafone$clone(),
  resampling = uninstantiate_resampling(
    make_outer_resampling(
      task_ul_vodafone,
      dataset_ul,
      drive_ids_train=1:7,
      drive_ids_test=8:10
    )
  ),
  measure = msr("regr.mae"),
  standardize = TRUE,
  nmc=num_permutation_sims_ul
)
filter_permutation_vodafone_ul$calculate(task_ul_vodafone)
permutation_ul_vodafone = tibble(
  as.data.table(filter_permutation_vodafone_ul)
) %>% mutate(provider="vodafone")

permutation_ul = bind_rows(
  permutation_ul_o2,
  permutation_ul_tmobile,
  permutation_ul_vodafone
)
```

Die ermittelten Werte können dann zur weiteren Analyse gespeichert werden.
```{r}
# write_csv(permutation_ul, str_c(results_dir, "feature_importance_xgboost_ul.csv"))
```


# Vorhersage der Download-Raten

Bei der Vorhersage der Download-Raten ist das Vorgehen analog.

## Einlesen der Daten

```{r}
dataset_dl = read_csv(
  str_c(data_dir, "dataset_dl.csv"), 
  col_types = cols(
    drive_id = col_integer(),
    scenario = col_factor(), 
    provider = col_factor(), 
    ci = col_factor(), 
    enodeb = col_factor()
  )
) %>% select(
  drive_id,
  timestamp,
  scenario,
  provider,
  velocity_mps,
  rsrp_dbm,
  rsrq_db,
  rssnr_db,
  cqi,
  ta,
  enodeb,
  f_mhz,
  payload_mb,
  throughput_mbits
) %>% drop_na() %>% rowid_to_column(var="row_id_original")
```

```{r}
dataset_dl_o2 = filter(dataset_dl, provider=="o2")
glimpse(dataset_dl_o2)

dataset_dl_tmobile = filter(dataset_dl, provider=="tmobile")
glimpse(dataset_dl_tmobile)

dataset_dl_vodafone = filter(dataset_dl, provider=="vodafone")
glimpse(dataset_dl_vodafone)
```

## Vorhersage-Tasks für jeden Provider

```{r}
task_dl_o2 = make_task(dataset_dl_o2, "task_dl_o2")
task_dl_o2

task_dl_tmobile = make_task(dataset_dl_tmobile, "task_dl_tmobile")
task_dl_tmobile

task_dl_vodafone = make_task(dataset_dl_vodafone, "task_dl_vodafone")
task_dl_vodafone
```

## Parameter Tuning

```{r, results = "hide"}
tuning_evals_dl = 50

tuning_result_dl_o2 = get_tuning_result(
  task_dl_o2,
  dataset_dl,
  grid_resolution = 20,
  n_evals = tuning_evals_dl
)
tuning_result_dl_tmobile = get_tuning_result(
  task_dl_tmobile,
  dataset_dl,
  grid_resolution = 20,
  n_evals = tuning_evals_dl
)
tuning_result_dl_vodafone = get_tuning_result(
  task_dl_vodafone,
  dataset_dl,
  grid_resolution = 20,
  n_evals = tuning_evals_dl
)
```

```{r}
tuning_result_dl = bind_rows(
  tibble(tuning_result_dl_o2$result) %>% mutate(provider="o2"),
  tibble(tuning_result_dl_tmobile$result) %>% mutate(provider="tmobile"),
  tibble(tuning_result_dl_vodafone$result) %>% mutate(provider="vodafone"),
) %>% select(
  "provider",
  "regr.xgboost.nrounds",
  "regr.xgboost.eta",
  "regr.xgboost.gamma",
  "regr.xgboost.lambda"
)

knitr::kable(tuning_result_dl)
```

## Parametrisierung der Lernalgorithmen mit den gefundenen Hyperparametern

```{r}
learner_dl_o2 = make_learner(
  nrounds = tuning_result_dl_o2$result$regr.xgboost.nrounds,
  eta = tuning_result_dl_o2$result$regr.xgboost.eta,
  gamma = tuning_result_dl_o2$result$regr.xgboost.gamma,
  lambda = tuning_result_dl_o2$result$regr.xgboost.lambda
)

learner_dl_tmobile = make_learner(
  nrounds = tuning_result_dl_tmobile$result$regr.xgboost.nrounds,
  eta = tuning_result_dl_tmobile$result$regr.xgboost.eta,
  gamma = tuning_result_dl_tmobile$result$regr.xgboost.gamma,
  lambda = tuning_result_dl_tmobile$result$regr.xgboost.lambda
)

learner_dl_vodafone = make_learner(
  nrounds = tuning_result_dl_vodafone$result$regr.xgboost.nrounds,
  eta = tuning_result_dl_vodafone$result$regr.xgboost.eta,
  gamma = tuning_result_dl_vodafone$result$regr.xgboost.gamma,
  lambda = tuning_result_dl_vodafone$result$regr.xgboost.lambda
)
```

## Validierung

```{r, results = "hide"}
resampling_result_dl_o2 = resample(
  task = task_dl_o2,
  learner = learner_dl_o2,
  resampling = make_outer_resampling(
    task_dl_o2,
    dataset_dl,
    drive_ids_train=1:7,
    drive_ids_test=8:10
  ),
  store_models = TRUE
)

resampling_result_dl_tmobile = resample(
  task = task_dl_tmobile,
  learner = learner_dl_tmobile,
  resampling = make_outer_resampling(
    task_dl_tmobile,
    dataset_dl,
    drive_ids_train=1:7,
    drive_ids_test=8:10
  ),
  store_models = TRUE
)

resampling_result_dl_vodafone = resample(
  task = task_dl_vodafone,
  learner = learner_dl_vodafone,
  resampling = make_outer_resampling(
    task_dl_vodafone,
    dataset_dl,
    drive_ids_train=1:7,
    drive_ids_test=8:10
  ),
  store_models = TRUE
)
```

```{r}
predictions_dl_o2 = as.data.table(resampling_result_dl_o2$prediction())
glimpse(tibble(predictions_dl_o2))
predictions_dl_tmobile = as.data.table(resampling_result_dl_tmobile$prediction())
predictions_dl_vodafone = as.data.table(resampling_result_dl_vodafone$prediction())
```

```{r}
validation_results_dl = bind_rows(
  tibble(predictions_dl_o2) %>% 
    inner_join(tibble(task_dl_o2$row_names), by="row_id") %>% 
    inner_join(dataset_dl, by=c("row_name"="row_id_original")),
  tibble(predictions_dl_tmobile) %>% 
    inner_join(tibble(task_dl_tmobile$row_names), by="row_id") %>% 
    inner_join(dataset_dl, by=c("row_name"="row_id_original")),
  tibble(predictions_dl_vodafone) %>% 
    inner_join(tibble(task_dl_vodafone$row_names), by="row_id") %>% 
    inner_join(dataset_dl, by=c("row_name"="row_id_original"))
)
glimpse(validation_results_dl)
```

```{r}
all(validation_results_dl$truth == validation_results_dl$throughput_mbits)
```

```{r}
validation_results_dl = validation_results_dl %>% 
  rename(prediction_xgboost=response) %>% 
  select(-truth, -row_id, -row_name)

# write_csv(validation_results_dl, str_c(results_dir, "predictions_xgboost_dl.csv"))
```

### Scatter Plots

```{r}
ggplot(
  filter(validation_results_dl, provider=="o2"),
  aes(x=throughput_mbits, y=prediction_xgboost)
) +
  geom_point(aes(color=scenario, shape=scenario)) +
  xlab("Measured Data Rate [MBit/s]") +
  ylab("Predicted Data Rate [MBit/s]") +
  ggtitle("Download-Rate Predictions for Provider O2")
```

```{r}
ggplot(
  filter(validation_results_dl, provider=="tmobile"),
  aes(x=throughput_mbits, y=prediction_xgboost)
) +
  geom_point(aes(color=scenario, shape=scenario)) +
  xlab("Measured Data Rate [MBit/s]") +
  ylab("Predicted Data Rate [MBit/s]") +
  ggtitle("Download-Rate Predictions for Provider T-Mobile")
```

```{r}
ggplot(
  filter(validation_results_dl, provider=="vodafone"),
  aes(x=throughput_mbits, y=prediction_xgboost)
) +
  geom_point(aes(color=scenario, shape=scenario)) +
  xlab("Measured Data Rate [MBit/s]") +
  ylab("Predicted Data Rate [MBit/s]") +
  ggtitle("Download-Rate Predictions for Provider Vodafone")
```

## Relevanz der Kovariablen

### Permutation Feature Importance

```{r, results='hide'}
num_permutation_sims_dl = 5

filter_permutation_o2_dl = flt("permutation",
  learner = learner_dl_o2$clone(),
  resampling = uninstantiate_resampling(
    make_outer_resampling(
      task_dl_o2,
      dataset_dl,
      drive_ids_train=1:7,
      drive_ids_test=8:10
    )
  ),
  measure = msr("regr.mae"),
  standardize = TRUE,
  nmc = num_permutation_sims_dl
)
filter_permutation_o2_dl$calculate(task_dl_o2)
permutation_dl_o2 = tibble(
  as.data.table(filter_permutation_o2_dl)
) %>% mutate(provider="o2")

filter_permutation_tmobile_dl = flt("permutation",
  learner = learner_dl_tmobile$clone(),
  resampling = uninstantiate_resampling(
    make_outer_resampling(
      task_dl_tmobile,
      dataset_dl,
      drive_ids_train=1:7,
      drive_ids_test=8:10
    )
  ),
  measure = msr("regr.mae"),
  standardize = TRUE,
  nmc = num_permutation_sims_dl
)
filter_permutation_tmobile_dl$calculate(task_dl_tmobile)
permutation_dl_tmobile = tibble(
  as.data.table(filter_permutation_tmobile_dl)
) %>% mutate(provider="tmobile")

filter_permutation_vodafone_dl = flt("permutation",
  learner = learner_dl_vodafone$clone(),
  resampling = uninstantiate_resampling(
    make_outer_resampling(
      task_dl_vodafone,
      dataset_dl,
      drive_ids_train=1:7,
      drive_ids_test=8:10
    )
  ),
  measure = msr("regr.mae"),
  standardize = TRUE,
  nmc = num_permutation_sims_dl
)
filter_permutation_vodafone_dl$calculate(task_dl_vodafone)
permutation_dl_vodafone = tibble(
  as.data.table(filter_permutation_vodafone_dl)
) %>% mutate(provider="vodafone")

permutation_dl = bind_rows(
  permutation_dl_o2,
  permutation_dl_tmobile,
  permutation_dl_vodafone
)
```

```{r}
# write_csv(permutation_dl, str_c(results_dir, "feature_importance_xgboost_dl.csv"))
```


# Vorhersage der eNodeB-Verbindungsdauern

## Einlesen der Daten

```{r}
dataset_linklifetime = read_csv(
  str_c(data_dir, "dataset_context.csv"), 
  col_types = cols(
    drive_id = col_integer(),
    scenario = col_factor(), 
    provider = col_factor(), 
    ci = col_factor(), 
    enodeb = col_factor()
  )
) %>% select(
  drive_id,
  timestamp,
  scenario,
  provider,
  velocity_mps,
  rsrp_dbm,
  rsrq_db,
  rssnr_db,
  cqi,
  ta,
  enodeb,
  rsrp_neighbor,
  rsrq_neighbor,
  link_lifetime
) %>% drop_na() %>% rowid_to_column(var="row_id_original")
```

```{r}
dataset_linklifetime_o2 = filter(dataset_linklifetime, provider=="o2")
glimpse(dataset_linklifetime_o2)

dataset_linklifetime_tmobile = filter(dataset_linklifetime, provider=="tmobile")
glimpse(dataset_linklifetime_tmobile)

dataset_linklifetime_vodafone = filter(dataset_linklifetime, provider=="vodafone")
glimpse(dataset_linklifetime_vodafone)
```

## Vorhersage-Tasks für jeden Provider

```{r}
task_linklifetime_o2 = make_task(
  dataset_linklifetime_o2,
  "task_linklifetime_o2",
  target = "link_lifetime"
)
task_linklifetime_o2

task_linklifetime_tmobile = make_task(
  dataset_linklifetime_tmobile,
  "task_linklifetime_tmobile",
  target = "link_lifetime"
)
task_linklifetime_tmobile

task_linklifetime_vodafone = make_task(
  dataset_linklifetime_vodafone,
  "task_linklifetime_vodafone",
  target = "link_lifetime"
)
task_linklifetime_vodafone
```

## Parameter Tuning

```{r, results = "hide"}
tuning_evals_linklifetime = 50

tuning_result_linklifetime_o2 = get_tuning_result(
  task_linklifetime_o2,
  dataset_linklifetime,
  grid_resolution = 20,
  n_evals = tuning_evals_linklifetime
)

tuning_result_linklifetime_tmobile = get_tuning_result(
  task_linklifetime_tmobile,
  dataset_linklifetime,
  grid_resolution = 20,
  n_evals = tuning_evals_linklifetime
)

tuning_result_linklifetime_vodafone = get_tuning_result(
  task_linklifetime_vodafone,
  dataset_linklifetime,
  grid_resolution = 20,
  n_evals = tuning_evals_linklifetime
)
```

```{r}
tuning_result_linklifetime = bind_rows(
  tibble(tuning_result_linklifetime_o2$result) %>% mutate(provider="o2"),
  tibble(tuning_result_linklifetime_tmobile$result) %>% mutate(provider="tmobile"),
  tibble(tuning_result_linklifetime_vodafone$result) %>% mutate(provider="vodafone"),
) %>% select(
  "provider",
  "regr.xgboost.nrounds",
  "regr.xgboost.eta",
  "regr.xgboost.gamma",
  "regr.xgboost.lambda"
)

knitr::kable(tuning_result_linklifetime)
```

## Parametrisierung der Lernalgorithmen mit den gefundenen Hyperparametern

```{r}
learner_linklifetime_o2 = make_learner(
  nrounds = tuning_result_linklifetime_o2$result$regr.xgboost.nrounds,
  eta = tuning_result_linklifetime_o2$result$regr.xgboost.eta,
  gamma = tuning_result_linklifetime_o2$result$regr.xgboost.gamma,
  lambda = tuning_result_linklifetime_o2$result$regr.xgboost.lambda
)

learner_linklifetime_tmobile = make_learner(
  nrounds = tuning_result_linklifetime_tmobile$result$regr.xgboost.nrounds,
  eta = tuning_result_linklifetime_tmobile$result$regr.xgboost.eta,
  gamma = tuning_result_linklifetime_tmobile$result$regr.xgboost.gamma,
  lambda = tuning_result_linklifetime_tmobile$result$regr.xgboost.lambda
)

learner_linklifetime_vodafone = make_learner(
  nrounds = tuning_result_linklifetime_vodafone$result$regr.xgboost.nrounds,
  eta = tuning_result_linklifetime_vodafone$result$regr.xgboost.eta,
  gamma = tuning_result_linklifetime_vodafone$result$regr.xgboost.gamma,
  lambda = tuning_result_linklifetime_vodafone$result$regr.xgboost.lambda
)
```

## Validierung

```{r, results = "hide"}
resampling_result_linklifetime_o2 = resample(
  task = task_linklifetime_o2,
  learner = learner_linklifetime_o2,
  resampling = make_outer_resampling(
    task_linklifetime_o2,
    dataset_linklifetime,
    drive_ids_train=1:7,
    drive_ids_test=8:10
  ),
  store_models = TRUE
)

resampling_result_linklifetime_tmobile = resample(
  task = task_linklifetime_tmobile,
  learner = learner_linklifetime_tmobile,
  resampling = make_outer_resampling(
    task_linklifetime_tmobile,
    dataset_linklifetime,
    drive_ids_train=1:7,
    drive_ids_test=8:10
  ),
  store_models = TRUE
)

resampling_result_linklifetime_vodafone = resample(
  task = task_linklifetime_vodafone,
  learner = learner_linklifetime_vodafone,
  resampling = make_outer_resampling(
    task_linklifetime_vodafone,
    dataset_linklifetime,
    drive_ids_train=1:7,
    drive_ids_test=8:10
  ),
  store_models = TRUE
)
```

```{r}
predictions_linklifetime_o2 = as.data.table(
  resampling_result_linklifetime_o2$prediction()
)
glimpse(tibble(predictions_linklifetime_o2))
predictions_linklifetime_tmobile = as.data.table(
  resampling_result_linklifetime_tmobile$prediction()
)
predictions_linklifetime_vodafone = as.data.table(
  resampling_result_linklifetime_vodafone$prediction()
)
```

```{r}
validation_results_linklifetime = bind_rows(
  tibble(predictions_linklifetime_o2) %>% 
    inner_join(tibble(task_linklifetime_o2$row_names), by="row_id") %>% 
    inner_join(dataset_linklifetime, by=c("row_name"="row_id_original")),
  tibble(predictions_linklifetime_tmobile) %>% 
    inner_join(tibble(task_linklifetime_tmobile$row_names), by="row_id") %>% 
    inner_join(dataset_linklifetime, by=c("row_name"="row_id_original")),
  tibble(predictions_linklifetime_vodafone) %>% 
    inner_join(tibble(task_linklifetime_vodafone$row_names), by="row_id") %>% 
    inner_join(dataset_linklifetime, by=c("row_name"="row_id_original"))
)
glimpse(validation_results_linklifetime)
```

```{r}
all(validation_results_linklifetime$truth == validation_results_linklifetime$link_lifetime)
```

```{r}
validation_results_linklifetime = validation_results_linklifetime %>% 
  rename(prediction_xgboost=response) %>% 
  select(-truth, -row_id, -row_name)

# write_csv(
#   validation_results_linklifetime,
#   str_c(results_dir, "predictions_xgboost_linklifetime.csv")
# )
```

### Scatter Plots

```{r}
ggplot(
  filter(validation_results_linklifetime, provider=="o2"), 
  aes(x=link_lifetime, y=prediction_xgboost)
) +
  geom_point(aes(color=scenario, shape=scenario)) +
  xlab("Measured Link-Lifetime [s]") +
  ylab("Predicted Link-Lifetime [s]") +
  ggtitle("Link-Lifetime Predictions for Provider O2")
```

```{r}
ggplot(
  filter(validation_results_linklifetime, provider=="tmobile"), 
  aes(x=link_lifetime, y=prediction_xgboost)
) +
  geom_point(aes(color=scenario, shape=scenario)) +
  xlab("Measured Link-Lifetime [s]") +
  ylab("Predicted Link-Lifetime [s]") +
  ggtitle("Link-Lifetime Predictions for Provider T-Mobile")
```

```{r}
ggplot(
  filter(validation_results_linklifetime, provider=="vodafone"),
  aes(x=link_lifetime, y=prediction_xgboost)
) +
  geom_point(aes(color=scenario, shape=scenario)) +
  xlab("Measured Link-Lifetime [s]") +
  ylab("Predicted Link-Lifetime [s]") +
  ggtitle("Link-Lifetime Predictions for Provider Vodafone")
```

## Relevanz der Kovariablen

### Permutation Feature Importance

```{r, results='hide'}
num_permutation_sims_linklifetime = 5

filter_permutation_o2_linklifetime = flt("permutation",
  learner = learner_linklifetime_o2$clone(),
  resampling = uninstantiate_resampling(
    make_outer_resampling(
      task_linklifetime_o2,
      dataset_linklifetime,
      drive_ids_train=1:7,
      drive_ids_test=8:10
    )
  ),
  measure = msr("regr.mae"),
  standardize = TRUE,
  nmc = num_permutation_sims_linklifetime
)
filter_permutation_o2_linklifetime$calculate(task_linklifetime_o2)
permutation_linklifetime_o2 = tibble(
  as.data.table(filter_permutation_o2_linklifetime)
) %>% mutate(provider="o2")

filter_permutation_tmobile_linklifetime = flt("permutation",
  learner = learner_linklifetime_tmobile$clone(),
  resampling = uninstantiate_resampling(
    make_outer_resampling(
      task_linklifetime_tmobile,
      dataset_linklifetime,
      drive_ids_train=1:7,
      drive_ids_test=8:10
    )
  ),
  measure = msr("regr.mae"),
  standardize = TRUE,
  nmc = num_permutation_sims_linklifetime
)
filter_permutation_tmobile_linklifetime$calculate(task_linklifetime_tmobile)
permutation_linklifetime_tmobile = tibble(
  as.data.table(filter_permutation_tmobile_linklifetime)
) %>% mutate(provider="tmobile")

filter_permutation_vodafone_linklifetime = flt("permutation",
  learner = learner_linklifetime_vodafone$clone(),
  resampling = uninstantiate_resampling(
    make_outer_resampling(
      task_linklifetime_vodafone,
      dataset_linklifetime,
      drive_ids_train=1:7,
      drive_ids_test=8:10
    )
  ),
  measure = msr("regr.mae"),
  standardize = TRUE,
  nmc = num_permutation_sims_linklifetime
)
filter_permutation_vodafone_linklifetime$calculate(task_linklifetime_vodafone)
permutation_linklifetime_vodafone = tibble(
  as.data.table(filter_permutation_vodafone_linklifetime)
) %>% mutate(provider="vodafone")

permutation_linklifetime = bind_rows(
  permutation_linklifetime_o2,
  permutation_linklifetime_tmobile,
  permutation_linklifetime_vodafone
)
```

```{r}
# write_csv(
#   permutation_linklifetime,
#   str_c(results_dir, "feature_importance_xgboost_linklifetime.csv")
# )
```